#!/usr/bin/env python3
"""
æ™ºèƒ½æ¨èç³»ç»Ÿæ•°æ®åº“è¿ç§»è„šæœ¬
ä¸ºç°æœ‰æ•°æ®åº“æ·»åŠ æ™ºèƒ½äº¤äº’è¿½è¸ªå’Œæ¨èåŠŸèƒ½æ‰€éœ€çš„è¡¨ç»“æ„
"""
import sqlite3
import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import DATABASE_PATH


def migrate_recommendation_tables():
    """è¿ç§»æ¨èç³»ç»Ÿæ‰€éœ€çš„æ•°æ®åº“è¡¨"""
    
    print("ğŸš€ å¼€å§‹æ™ºèƒ½æ¨èç³»ç»Ÿæ•°æ®åº“è¿ç§»...")
    
    if not os.path.exists(DATABASE_PATH):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DATABASE_PATH}")
        return False
    
    try:
        # å¤‡ä»½åŸæ•°æ®åº“
        backup_path = f"{DATABASE_PATH}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        with open(DATABASE_PATH, 'rb') as src, open(backup_path, 'wb') as dst:
            dst.write(src.read())
        
        print(f"âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
        
        # è¿æ¥æ•°æ®åº“
        conn = sqlite3.connect(DATABASE_PATH)
        c = conn.cursor()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
        c.execute("SELECT name FROM sqlite_master WHERE type='table'")
        existing_tables = {row[0] for row in c.fetchall()}
        
        tables_to_create = []
        
        # 1. è®ºæ–‡äº¤äº’è®°å½•è¡¨
        if 'paper_interactions' not in existing_tables:
            tables_to_create.append(('paper_interactions', '''
                CREATE TABLE paper_interactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    paper_id INTEGER NOT NULL,
                    interaction_type TEXT NOT NULL,
                    duration_seconds INTEGER DEFAULT 0,
                    scroll_depth_percent INTEGER DEFAULT 0,  
                    click_count INTEGER DEFAULT 0,
                    session_id TEXT,
                    user_agent TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (paper_id) REFERENCES papers (id)
                )
            '''))
        
        # 2. è®ºæ–‡å…´è¶£è¯„åˆ†è¡¨
        if 'paper_interest_scores' not in existing_tables:
            tables_to_create.append(('paper_interest_scores', '''
                CREATE TABLE paper_interest_scores (
                    paper_id INTEGER PRIMARY KEY,
                    interest_score INTEGER DEFAULT 0,
                    interaction_count INTEGER DEFAULT 0,
                    total_view_time INTEGER DEFAULT 0,
                    max_scroll_depth INTEGER DEFAULT 0,
                    last_interaction_at TIMESTAMP,
                    bookmark_count INTEGER DEFAULT 0,
                    explicit_interest INTEGER DEFAULT 0,  -- 1: æ˜ç¡®æ„Ÿå…´è¶£, -1: æ˜ç¡®ä¸æ„Ÿå…´è¶£, 0: ä¸­æ€§
                    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (paper_id) REFERENCES papers (id)
                )
            '''))
        
        # 3. ç”¨æˆ·å…´è¶£æ¨¡å¼è¡¨
        if 'user_interest_patterns' not in existing_tables:
            tables_to_create.append(('user_interest_patterns', '''
                CREATE TABLE user_interest_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_type TEXT NOT NULL,  -- 'keyword', 'author', 'journal', 'topic'
                    pattern_value TEXT NOT NULL,
                    interest_strength REAL DEFAULT 0.0,  -- 0.0-1.0 å…´è¶£å¼ºåº¦
                    occurrence_count INTEGER DEFAULT 0,
                    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(pattern_type, pattern_value)
                )
            '''))
        
        # åˆ›å»ºæ–°è¡¨
        for table_name, create_sql in tables_to_create:
            print(f"ğŸ“ åˆ›å»ºè¡¨: {table_name}")
            c.execute(create_sql)
        
        # åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
        indices_to_create = [
            ("idx_paper_interactions_paper_id", "CREATE INDEX IF NOT EXISTS idx_paper_interactions_paper_id ON paper_interactions (paper_id)"),
            ("idx_paper_interactions_type", "CREATE INDEX IF NOT EXISTS idx_paper_interactions_type ON paper_interactions (interaction_type)"),
            ("idx_paper_interactions_created", "CREATE INDEX IF NOT EXISTS idx_paper_interactions_created ON paper_interactions (created_at)"),
            ("idx_paper_interest_scores_score", "CREATE INDEX IF NOT EXISTS idx_paper_interest_scores_score ON paper_interest_scores (interest_score)"),
            ("idx_user_patterns_type_value", "CREATE INDEX IF NOT EXISTS idx_user_patterns_type_value ON user_interest_patterns (pattern_type, pattern_value)"),
        ]
        
        print("ğŸ“Š åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•...")
        for index_name, create_sql in indices_to_create:
            try:
                c.execute(create_sql)
                print(f"  âœ… {index_name}")
            except sqlite3.Error as e:
                print(f"  âš ï¸ {index_name}: {e}")
        
        # æäº¤æ›´æ”¹
        conn.commit()
        
        # éªŒè¯è¿ç§»ç»“æœ
        c.execute("SELECT name FROM sqlite_master WHERE type='table'")
        final_tables = {row[0] for row in c.fetchall()}
        
        expected_new_tables = {'paper_interactions', 'paper_interest_scores', 'user_interest_patterns'}
        created_tables = expected_new_tables & final_tables
        
        print(f"\nâœ… è¿ç§»å®Œæˆï¼")
        print(f"ğŸ“‹ æ–°åˆ›å»ºçš„è¡¨: {', '.join(created_tables)}")
        
        if len(created_tables) == len(expected_new_tables):
            print("ğŸ‰ æ‰€æœ‰æ¨èç³»ç»Ÿè¡¨å·²æˆåŠŸåˆ›å»º")
            
            # æ’å…¥ä¸€äº›ç¤ºä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰
            if input("\næ˜¯å¦è¦æ’å…¥ç¤ºä¾‹äº¤äº’æ•°æ®ç”¨äºæµ‹è¯•ï¼Ÿ(y/N): ").lower() == 'y':
                insert_sample_data(c)
                conn.commit()
                print("âœ… ç¤ºä¾‹æ•°æ®å·²æ’å…¥")
            
            return True
        else:
            missing_tables = expected_new_tables - created_tables
            print(f"âš ï¸ ä»¥ä¸‹è¡¨åˆ›å»ºå¤±è´¥: {', '.join(missing_tables)}")
            return False
            
    except Exception as e:
        print(f"âŒ è¿ç§»å¤±è´¥: {e}")
        return False
    finally:
        conn.close()


def insert_sample_data(cursor):
    """æ’å…¥ç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•"""
    try:
        # è·å–ä¸€äº›è®ºæ–‡ID
        cursor.execute("SELECT id FROM papers LIMIT 5")
        paper_ids = [row[0] for row in cursor.fetchall()]
        
        if not paper_ids:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è®ºæ–‡æ•°æ®ï¼Œè·³è¿‡ç¤ºä¾‹æ•°æ®æ’å…¥")
            return
        
        print("ğŸ“ æ’å…¥ç¤ºä¾‹äº¤äº’æ•°æ®...")
        
        # æ’å…¥ä¸€äº›ç¤ºä¾‹äº¤äº’è®°å½•
        sample_interactions = [
            (paper_ids[0], 'view_end', 120, 80, 'session_1'),  # æ·±åº¦é˜…è¯»
            (paper_ids[0], 'bookmark', 0, 0, 'session_1'),     # æ”¶è—
            (paper_ids[1], 'view_end', 30, 40, 'session_2'),   # ç®€å•æµè§ˆ
            (paper_ids[2], 'view_end', 5, 10, 'session_3'),    # å¿«é€Ÿè·³è¿‡
            (paper_ids[3], 'view_end', 180, 95, 'session_4'),  # é•¿æ—¶é—´ç ”ç©¶
            (paper_ids[3], 'click_pdf', 0, 0, 'session_4'),    # ç‚¹å‡»PDF
            (paper_ids[4], 'explicit_dislike', 0, 0, 'session_5'),  # æ˜ç¡®ä¸å–œæ¬¢
        ]
        
        for paper_id, interaction_type, duration, scroll_depth, session_id in sample_interactions:
            cursor.execute('''
                INSERT INTO paper_interactions 
                (paper_id, interaction_type, duration_seconds, scroll_depth_percent, session_id, created_at)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (paper_id, interaction_type, duration, scroll_depth, session_id, datetime.now()))
        
        # æ’å…¥ä¸€äº›ç¤ºä¾‹å…´è¶£è¯„åˆ†
        sample_scores = [
            (paper_ids[0], 85, 2, 120, 80, 1, 1),  # é«˜å…´è¶£
            (paper_ids[1], 35, 1, 30, 40, 0, 0),   # ä¸­ç­‰å…´è¶£
            (paper_ids[2], 10, 1, 5, 10, 0, 0),    # ä½å…´è¶£
            (paper_ids[3], 90, 2, 180, 95, 0, 1),  # å¾ˆé«˜å…´è¶£
            (paper_ids[4], 5, 1, 0, 0, 0, -1),     # ä¸æ„Ÿå…´è¶£
        ]
        
        for score_data in sample_scores:
            cursor.execute('''
                INSERT INTO paper_interest_scores 
                (paper_id, interest_score, interaction_count, total_view_time, 
                 max_scroll_depth, bookmark_count, explicit_interest, calculated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (*score_data, datetime.now()))
        
        # æ’å…¥ä¸€äº›ç¤ºä¾‹å…´è¶£æ¨¡å¼
        sample_patterns = [
            ('keyword', 'machine learning', 0.8, 5),
            ('keyword', 'neural network', 0.7, 3),
            ('keyword', 'deep learning', 0.9, 4),
            ('author', 'John Smith', 0.6, 2),
            ('journal', 'IEEE Transactions', 0.7, 3),
        ]
        
        for pattern_type, pattern_value, strength, count in sample_patterns:
            cursor.execute('''
                INSERT OR IGNORE INTO user_interest_patterns 
                (pattern_type, pattern_value, interest_strength, occurrence_count, last_updated)
                VALUES (?, ?, ?, ?, ?)
            ''', (pattern_type, pattern_value, strength, count, datetime.now()))
        
        print("âœ… ç¤ºä¾‹æ•°æ®æ’å…¥å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ’å…¥ç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")


def check_migration_status():
    """æ£€æŸ¥è¿ç§»çŠ¶æ€"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        c = conn.cursor()
        
        c.execute("SELECT name FROM sqlite_master WHERE type='table'")
        existing_tables = {row[0] for row in c.fetchall()}
        
        required_tables = {'paper_interactions', 'paper_interest_scores', 'user_interest_patterns'}
        missing_tables = required_tables - existing_tables
        
        if not missing_tables:
            print("âœ… æ¨èç³»ç»Ÿæ•°æ®åº“è¡¨å·²å­˜åœ¨ï¼Œæ— éœ€è¿ç§»")
            
            # æ£€æŸ¥æ•°æ®é‡
            for table in required_tables:
                c.execute(f"SELECT COUNT(*) FROM {table}")
                count = c.fetchone()[0]
                print(f"ğŸ“Š {table}: {count} æ¡è®°å½•")
            
            return True
        else:
            print(f"âš ï¸ ç¼ºå°‘ä»¥ä¸‹è¡¨: {', '.join(missing_tables)}")
            return False
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
        return False
    finally:
        conn.close()


if __name__ == "__main__":
    print("ğŸ¤– æ™ºèƒ½æ¨èç³»ç»Ÿæ•°æ®åº“è¿ç§»å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰çŠ¶æ€
    if check_migration_status():
        if input("è¡¨å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦é‡æ–°åˆ›å»ºï¼Ÿ(y/N): ").lower() != 'y':
            print("âœ… è¿ç§»å·²å®Œæˆï¼Œé€€å‡º")
            sys.exit(0)
    
    # æ‰§è¡Œè¿ç§»
    success = migrate_recommendation_tables()
    
    if success:
        print("\nğŸ‰ æ™ºèƒ½æ¨èç³»ç»Ÿè¿ç§»æˆåŠŸï¼")
        print("\nğŸ“‹ ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–°åŠŸèƒ½ï¼š")
        print("   â€¢ æ™ºèƒ½äº¤äº’è¿½è¸ª")
        print("   â€¢ åŸºäºè¡Œä¸ºçš„ä¸ªæ€§åŒ–æ¨è") 
        print("   â€¢ è®ºæ–‡å…´è¶£è¯„åˆ†")
        print("   â€¢ ç”¨æˆ·å…´è¶£æ¨¡å¼åˆ†æ")
        print("\nğŸŒ æ–°çš„APIæ¥å£ï¼š")
        print("   â€¢ POST /api/interactions/track - è®°å½•äº¤äº’")
        print("   â€¢ GET  /api/recommendations/personalized - ä¸ªæ€§åŒ–æ¨è")
        print("   â€¢ GET  /api/recommendations/similar/<paper_id> - ç›¸ä¼¼è®ºæ–‡")
        print("   â€¢ GET  /api/interactions/stats - äº¤äº’ç»Ÿè®¡")
        print("   â€¢ GET  /api/recommendations/dashboard - æ¨èä»ªè¡¨æ¿")
    else:
        print("\nâŒ è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)
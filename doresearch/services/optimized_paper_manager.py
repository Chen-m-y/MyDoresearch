"""
ä¼˜åŒ–ç‰ˆè®ºæ–‡ç®¡ç†æœåŠ¡ - ä½¿ç”¨è¿æ¥æ± å’Œæ‰¹é‡æ“ä½œ
è§£å†³N+1æŸ¥è¯¢é—®é¢˜å’Œæ•°æ®åº“è¿æ¥é‡å¤åˆ›å»ºé—®é¢˜
"""
import hashlib
import re
import requests
import json
from datetime import datetime
from typing import Dict, List, Optional
from services.database_service import get_database_service


class OptimizedPaperManager:
    """ä¼˜åŒ–ç‰ˆè®ºæ–‡ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.db_service = get_database_service()
    
    def add_feed(self, name: str, url: str, journal: str = "") -> Dict:
        """æ·»åŠ è®ºæ–‡æº"""
        try:
            feed_id = self.db_service.execute_insert(
                'INSERT INTO feeds (name, url, journal) VALUES (?, ?, ?)',
                (name, url, journal)
            )
            return {'success': True, 'feed_id': feed_id}
        except Exception as e:
            if 'UNIQUE constraint failed' in str(e):
                return {'success': False, 'error': 'APIåœ°å€å·²å­˜åœ¨'}
            return {'success': False, 'error': str(e)}
    
    def get_all_feeds(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è®ºæ–‡æºï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
        cache_key = "all_feeds"
        return self.db_service.get_cached_query(
            cache_key,
            'SELECT * FROM feeds WHERE active = 1 ORDER BY name',
            cache_duration=300
        )
    
    def update_feed(self, feed_id: int) -> Dict:
        """æ›´æ–°æŒ‡å®šè®ºæ–‡æºçš„æ–‡ç« ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰"""
        # è·å–è®ºæ–‡æºä¿¡æ¯
        feed = self.db_service.execute_query(
            'SELECT * FROM feeds WHERE id = ?', 
            (feed_id,), 
            fetch_one=True
        )
        
        if not feed:
            return {'success': False, 'error': 'è®ºæ–‡æºä¸å­˜åœ¨'}
        
        try:
            response = requests.get(feed['url'], timeout=30)
            response.raise_for_status()
            papers_data = response.json()
            
            if not isinstance(papers_data, list):
                return {'success': False, 'error': 'APIå“åº”æ ¼å¼é”™è¯¯ï¼Œåº”è¯¥æ˜¯æ•°ç»„æ ¼å¼'}
            
            # æ‰¹é‡å¤„ç†è®ºæ–‡æ•°æ®
            new_papers = self._batch_insert_papers(feed_id, feed, papers_data)
            
            # æ›´æ–°è®ºæ–‡æºæœ€åæ›´æ–°æ—¶é—´
            self.db_service.execute_update(
                'UPDATE feeds SET last_updated = CURRENT_TIMESTAMP WHERE id = ?',
                (feed_id,)
            )
            
            # æ¸…ç†ç›¸å…³ç¼“å­˜
            self.db_service.clear_cache("all_feeds")
            
            return {'success': True, 'new_papers': new_papers}
            
        except requests.RequestException as e:
            return {'success': False, 'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'}
        except json.JSONDecodeError as e:
            return {'success': False, 'error': f'JSONè§£æå¤±è´¥: {str(e)}'}
        except Exception as e:
            return {'success': False, 'error': f'æ›´æ–°å¤±è´¥: {str(e)}'}
    
    def _batch_insert_papers(self, feed_id: int, feed: Dict, papers_data: List[Dict]) -> int:
        """æ‰¹é‡æ’å…¥è®ºæ–‡æ•°æ®"""
        if not papers_data:
            return 0
        
        # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
        insert_params = []
        paper_hashes = []
        
        for paper_data in papers_data:
            if not paper_data.get('title'):
                continue
            
            # è®¡ç®—å“ˆå¸Œå€¼
            paper_hash = hashlib.md5(
                (paper_data.get('title', '') +
                 paper_data.get('url', '') +
                 str(paper_data.get('external_id', ''))).encode()
            ).hexdigest()
            
            paper_hashes.append(paper_hash)
            
            # å‡†å¤‡æ’å…¥å‚æ•°
            ieee_number = self._extract_ieee_number(paper_data)
            title = paper_data.get('title', '').strip()
            abstract = paper_data.get('abstract', '').strip()
            authors = paper_data.get('author', paper_data.get('authors', ''))
            journal = paper_data.get('journal') or feed['journal']
            url = paper_data.get('url', '')
            pdf_url = paper_data.get('pdf_url', '')
            doi = paper_data.get('doi', '')
            external_id = paper_data.get('id', '')
            published_date = self._parse_date_from_json(paper_data)
            status = paper_data.get('status', 'unread')
            current_time = datetime.now().isoformat()
            
            insert_params.append((
                feed_id, title, abstract, authors, journal, published_date,
                url, pdf_url, doi, status, current_time, paper_hash,
                external_id, ieee_number
            ))
        
        if not insert_params:
            return 0
        
        # æ‰¹é‡æ£€æŸ¥å·²å­˜åœ¨çš„å“ˆå¸Œ
        if paper_hashes:
            placeholders = ','.join(['?' for _ in paper_hashes])
            existing_hashes = self.db_service.execute_query(
                f'SELECT hash FROM papers WHERE hash IN ({placeholders})',
                tuple(paper_hashes),
                fetch_all=True
            )
            existing_hash_set = {row['hash'] for row in existing_hashes}
            
            # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„è®ºæ–‡
            filtered_params = []
            for params in insert_params:
                paper_hash = params[11]  # hashå­—æ®µçš„ä½ç½®
                if paper_hash not in existing_hash_set:
                    filtered_params.append(params)
            
            if not filtered_params:
                return 0
            
            # æ‰¹é‡æ’å…¥æ–°è®ºæ–‡
            insert_query = '''
                INSERT INTO papers
                (feed_id, title, abstract, authors, journal, published_date,
                 url, pdf_url, doi, status, status_changed_at, hash, external_id, ieee_article_number)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            '''
            
            self.db_service.execute_batch(insert_query, filtered_params)
            return len(filtered_params)
        
        return 0
    
    def _extract_ieee_number(self, paper_data: Dict) -> Optional[str]:
        """ä»è®ºæ–‡æ•°æ®ä¸­æå–IEEEæ–‡ç« ç¼–å·"""
        # 1. ç›´æ¥ä»å­—æ®µè·å–
        ieee_number = paper_data.get('ieee_article_number')
        if ieee_number:
            return ieee_number
        
        # 2. ä»DOIæå–
        doi = paper_data.get('doi')
        if doi and 'ieee' in doi.lower():
            ieee_match = re.search(r'(\d+)$', doi)
            if ieee_match:
                return ieee_match.group(1)
        
        # 3. ä»URLæå–
        url = paper_data.get('url')
        if url and 'ieee' in url.lower():
            ieee_match = re.search(r'/document/(\d+)', url)
            if ieee_match:
                return ieee_match.group(1)
        
        return None
    
    def _parse_date_from_json(self, paper_data: Dict) -> str:
        """ä»JSONæ•°æ®ä¸­è§£æå‘å¸ƒæ—¥æœŸ"""
        date_fields = ['published_at', 'published_date', 'date', 'created_at', 'updated_at', 'pub_date']
        
        for field in date_fields:
            date_value = paper_data.get(field)
            if date_value:
                try:
                    if isinstance(date_value, (int, float)):
                        return datetime.fromtimestamp(date_value).isoformat()
                    
                    if isinstance(date_value, str):
                        try:
                            # å¤„ç†ISOæ ¼å¼æ—¶é—´ï¼ˆåŒ…å«Zåç¼€ï¼‰
                            if date_value.endswith('Z'):
                                date_value = date_value[:-1] + '+00:00'
                            return datetime.fromisoformat(date_value).isoformat()
                        except:
                            pass
                        
                        date_formats = [
                            '%Y-%m-%d',
                            '%Y-%m-%d %H:%M:%S',
                            '%Y-%m-%dT%H:%M:%S',
                            '%Y-%m-%dT%H:%M:%S.%f',
                            '%Y/%m/%d',
                            '%d/%m/%Y',
                            '%m/%d/%Y'
                        ]
                        
                        for fmt in date_formats:
                            try:
                                return datetime.strptime(date_value, fmt).isoformat()
                            except:
                                continue
                except:
                    continue
        
        return datetime.now().isoformat()
    
    def get_papers_by_feed(self, feed_id: int, status: str = None) -> List[Dict]:
        """è·å–æŒ‡å®šè®¢é˜…çš„è®ºæ–‡åˆ—è¡¨ï¼ˆä¼˜åŒ–æŸ¥è¯¢ï¼‰"""
        cache_key = f"papers_feed_{feed_id}_{status or 'all'}"
        
        if status:
            query = '''
                SELECT * FROM papers 
                WHERE feed_id = ? AND status = ? 
                ORDER BY published_date DESC
            '''
            params = (feed_id, status)
        else:
            query = '''
                SELECT * FROM papers 
                WHERE feed_id = ? 
                ORDER BY published_date DESC
            '''
            params = (feed_id,)
        
        return self.db_service.get_cached_query(cache_key, query, params, cache_duration=60)
    
    def get_paper(self, paper_id: int) -> Optional[Dict]:
        """è·å–å•ç¯‡è®ºæ–‡è¯¦æƒ…ï¼ˆåŒ…å«åˆ†æç»“æœï¼‰"""
        # è·å–è®ºæ–‡åŸºæœ¬ä¿¡æ¯
        paper = self.db_service.execute_query(
            'SELECT * FROM papers WHERE id = ?', 
            (paper_id,), 
            fetch_one=True
        )
        
        if not paper:
            return None
        
        # è·å–ç›¸å…³ä»»åŠ¡ä¿¡æ¯ï¼ˆä½¿ç”¨JOINä¼˜åŒ–ï¼‰
        task = self.db_service.execute_query(
            '''SELECT *
               FROM tasks
               WHERE paper_id = ? AND task_type = 'deep_analysis'
               ORDER BY created_at DESC LIMIT 1''',
            (paper_id,),
            fetch_one=True
        )
        
        if task:
            paper['analysis_task'] = task
            
            # è·å–ä»»åŠ¡æ­¥éª¤
            steps = self.db_service.execute_query(
                'SELECT * FROM task_steps WHERE task_id = ? ORDER BY id',
                (task['id'],),
                fetch_all=True
            )
            paper['analysis_task']['steps'] = steps
        
        return paper
    
    def update_paper_status(self, paper_id: int, status: str) -> Dict:
        """æ›´æ–°è®ºæ–‡çŠ¶æ€å¹¶è®°å½•å˜åŒ–æ—¶é—´"""
        # è·å–å½“å‰çŠ¶æ€
        current = self.db_service.execute_query(
            'SELECT status FROM papers WHERE id = ?', 
            (paper_id,), 
            fetch_one=True
        )
        
        if not current:
            return {'success': False, 'error': 'è®ºæ–‡ä¸å­˜åœ¨'}
        
        current_status = current['status']
        status_changed = current_status != status
        
        # æ ¹æ®çŠ¶æ€æ˜¯å¦å˜åŒ–å†³å®šæ›´æ–°ç­–ç•¥
        if status_changed:
            current_time = datetime.now().isoformat()
            affected_rows = self.db_service.execute_update(
                'UPDATE papers SET status = ?, status_changed_at = ? WHERE id = ?',
                (status, current_time, paper_id)
            )
            print(f"ğŸ“ è®ºæ–‡ {paper_id} çŠ¶æ€ä» '{current_status}' å˜æ›´ä¸º '{status}' (æ—¶é—´: {current_time})")
        else:
            affected_rows = self.db_service.execute_update(
                'UPDATE papers SET status = ? WHERE id = ?',
                (status, paper_id)
            )
        
        # æ¸…ç†ç›¸å…³ç¼“å­˜
        self._clear_paper_caches(paper_id)
        
        return {
            'success': affected_rows > 0, 
            'status_changed': status_changed
        }
    
    def translate_abstract(self, paper_id: int) -> Dict:
        """ç¿»è¯‘è®ºæ–‡æ‘˜è¦"""
        # è·å–è®ºæ–‡ä¿¡æ¯
        paper = self.db_service.execute_query(
            'SELECT abstract, abstract_cn FROM papers WHERE id = ?',
            (paper_id,),
            fetch_one=True
        )
        
        if not paper:
            return {'success': False, 'error': 'è®ºæ–‡ä¸å­˜åœ¨'}
        
        if paper['abstract_cn']:
            return {'success': True, 'translation': paper['abstract_cn'], 'cached': True}
        
        if not paper['abstract']:
            return {'success': False, 'error': 'è¯¥è®ºæ–‡æ²¡æœ‰æ‘˜è¦'}
        
        try:
            # å¯¼å…¥ç¿»è¯‘å™¨
            from services.deepseek_analyzer import DeepSeekAnalyzer
            analyzer = DeepSeekAnalyzer()
            
            translation = analyzer.translate_text(paper['abstract'])
            
            # æ›´æ–°ç¿»è¯‘ç»“æœ
            self.db_service.execute_update(
                'UPDATE papers SET abstract_cn = ? WHERE id = ?',
                (translation, paper_id)
            )
            
            return {'success': True, 'translation': translation, 'cached': False}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_paper_navigation(self, paper_id: int, feed_id: int) -> Optional[Dict]:
        """è·å–è®ºæ–‡å¯¼èˆªä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æŸ¥è¯¢è·å–å¯¼èˆªä¿¡æ¯
        nav_query = '''
            WITH ordered_papers AS (
                SELECT id, ROW_NUMBER() OVER (ORDER BY published_date DESC) as row_num
                FROM papers 
                WHERE feed_id = ?
            ),
            current_paper AS (
                SELECT row_num FROM ordered_papers WHERE id = ?
            )
            SELECT 
                (SELECT id FROM ordered_papers WHERE row_num = cp.row_num - 1) as prev_id,
                (SELECT id FROM ordered_papers WHERE row_num = cp.row_num + 1) as next_id,
                cp.row_num as current_index,
                (SELECT COUNT(*) FROM papers WHERE feed_id = ?) as total
            FROM current_paper cp
        '''
        
        result = self.db_service.execute_query(
            nav_query, 
            (feed_id, paper_id, feed_id), 
            fetch_one=True
        )
        
        if result:
            return {
                'prev_id': result['prev_id'],
                'next_id': result['next_id'],
                'current_index': result['current_index'],
                'total': result['total']
            }
        
        return None
    
    def get_status_change_history(self, paper_id: int) -> Optional[Dict]:
        """è·å–è®ºæ–‡çŠ¶æ€å˜åŒ–å†å²"""
        result = self.db_service.execute_query(
            '''SELECT status, status_changed_at, created_at
               FROM papers WHERE id = ?''',
            (paper_id,),
            fetch_one=True
        )
        
        if result:
            return {
                'current_status': result['status'],
                'status_changed_at': result['status_changed_at'],
                'created_at': result['created_at']
            }
        
        return None
    
    def get_papers_by_status_change_time(self, start_time: str = None, end_time: str = None) -> List[Dict]:
        """æ ¹æ®çŠ¶æ€å˜åŒ–æ—¶é—´è·å–è®ºæ–‡åˆ—è¡¨ï¼ˆä¼˜åŒ–æŸ¥è¯¢ï¼‰"""
        conditions = ['1=1']
        params = []
        
        if start_time:
            conditions.append('status_changed_at >= ?')
            params.append(start_time)
        
        if end_time:
            conditions.append('status_changed_at <= ?')
            params.append(end_time)
        
        query = f'''
            SELECT * FROM papers 
            WHERE {' AND '.join(conditions)}
            ORDER BY status_changed_at DESC
        '''
        
        return self.db_service.execute_query(query, tuple(params), fetch_all=True)
    
    def _clear_paper_caches(self, paper_id: int):
        """æ¸…ç†ä¸ç‰¹å®šè®ºæ–‡ç›¸å…³çš„ç¼“å­˜"""
        # æ¸…ç†è®ºæ–‡åˆ—è¡¨ç¼“å­˜
        self.db_service.clear_cache()  # ç®€åŒ–å¤„ç†ï¼Œæ¸…ç†æ‰€æœ‰ç¼“å­˜
    
    def get_database_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        return self.db_service.get_statistics()